# 👿 Keras 基本图像分类

---

本指南将训练一个神经网络模型，对运动鞋和衬衫等服装图像进行分类。即使您不理解所有细节也没关系；这只是对完整 TensorFlow 程序的快速概述，详细内容会在您实际操作的同时进行介绍。

本指南使用了 [tf.keras](https://tensorflow.google.cn/guide/keras?hl=zh_cn)，它是 TensorFlow 中用来构建和训练模型的高级 API。

```python
# TensorFlow and tf.keras
import tensorflow as tf
from tensorflow import keras

# Helper libraries
import numpy as np
import matplotlib.pyplot as plt

print(tf.__version__)
2.3.1
```

## 1. 导入 Fashion MNIST 数据集

本指南使用 [Fashion MNIST](https://github.com/zalandoresearch/fashion-mnist) 数据集，该数据集包含 10 个类别的 70,000 个灰度图像。这些图像以低分辨率（28x28 像素）展示了单件衣物，如下所示：

![](https://gitee.com/veal98/images/raw/master/img/20201104114844.png)

> 💡 Fashion MNIST 旨在临时替代经典 [MNIST](http://yann.lecun.com/exdb/mnist/) 数据集，后者常被用作计算机视觉机器学习程序的“Hello, World”。MNIST 数据集包含手写数字（0、1、2 等）的图像，其格式与您将使用的衣物图像的格式相同。

在本指南中，我们使用 60,000 个图像来训练网络，使用 10,000 个图像来评估网络学习对图像分类的准确率。您可以直接从 TensorFlow 访问 Fashion MNIST。请运行以下代码，直接从 TensorFlow 中导入和加载 Fashion MNIST 数据：

```python
fashion_mnist = keras.datasets.fashion_mnist

(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()
```

加载数据集会返回四个 NumPy 数组：

- `train_images` 和 `train_labels` 数组是*训练集*，即模型用于学习的数据。
- *测试集* `test_images` 和 `test_labels` 数组会被用来对模型进行测试。

图像是 28x28 的 NumPy 数组，像素值介于 0 到 255 之间。*标签*是整数数组，介于 0 到 9 之间。这些标签对应于图像所代表的服装*类*：

| 标签 | 类       |
| :--- | :------- |
| 0    | T恤/上衣 |
| 1    | 裤子     |
| 2    | 套头衫   |
| 3    | 连衣裙   |
| 4    | 外套     |
| 5    | 凉鞋     |
| 6    | 衬衫     |
| 7    | 运动鞋   |
| 8    | 包       |
| 9    | 短靴     |

每个图像都会被映射到一个标签。由于数据集不包括*类名称*，请将它们存储在下方，供稍后绘制图像时使用：

```python
class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',
               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']
```

## 2. 浏览数据

在训练模型之前，我们先浏览一下数据集的格式。以下代码显示训练集中有 60,000 个图像，每个图像由 28 x 28 的像素表示：

```python
train_images.shape
(60000, 28, 28)
```

同样，训练集中有 60,000 个标签：

```python
len(train_labels)
60000
```

每个标签都是一个 0 到 9 之间的整数：

```python
train_labels
array([9, 0, 0, ..., 3, 0, 5], dtype=uint8)
```

测试集中有 10,000 个图像。同样，每个图像都由 28x28 个像素表示：

```python
test_images.shape
(10000, 28, 28)
```

测试集包含 10,000 个图像标签：

```python
len(test_labels)
10000
```

## 3. 预处理数据

在训练网络之前，必须对数据进行预处理。如果您检查训练集中的第一个图像，您会看到像素值处于 0 到 255 之间：

```python
plt.figure()
plt.imshow(train_images[0])
plt.colorbar()
plt.grid(False)
plt.show()
```

<img src="https://gitee.com/veal98/images/raw/master/img/20201104203424.png" style="zoom:50%;" />

将这些值缩小至 0 到 1 之间（归一化），然后将其馈送到神经网络模型。为此，请将这些值除以 255。请务必以相同的方式对*训练集*和*测试集*进行预处理：

```python
train_images = train_images / 255.0

test_images = test_images / 255.0
```

为了验证数据的格式是否正确，以及您是否已准备好构建和训练网络，让我们显示*训练集*中的前 25 个图像，并在每个图像下方显示类名称。

```python
plt.figure(figsize=(10,10))
for i in range(25):
    plt.subplot(5,5,i+1)
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    plt.imshow(train_images[i])
    plt.xlabel(class_names[train_labels[i]])
plt.show()
```

<img src="https://gitee.com/veal98/images/raw/master/img/20201104203820.png" style="zoom: 50%;" />

## 4. 构建模型

构建神经网络需要先配置模型的层，然后再编译模型。

### ① 设置层

神经网络的基本组成部分是*层*。层会从向其馈送的数据中提取表示形式。希望这些表示形式有助于解决手头上的问题。

大多数深度学习都包括将简单的层链接在一起。大多数层（如 [`tf.keras.layers.Dense`](https://tensorflow.google.cn/api_docs/python/tf/keras/layers/Dense?hl=zh_cn)）都具有在训练期间才会学习的参数。

> 💡 使用 `Keras` 接口有以下 3 种方式构建模型：使用 `Sequential` 按层顺序构建模型，使用函数式 API 构建任意结构模型，继承 `Model` 基类构建自定义模型。
>
> 此处选择使用最简单的 `Sequential`，按层顺序模型。

```python
model = keras.Sequential([
    keras.layers.Flatten(input_shape=(28, 28)),
    keras.layers.Dense(128, activation='relu'),
    keras.layers.Dense(10)
])
```

该网络的第一层 [`tf.keras.layers.Flatten`](https://tensorflow.google.cn/api_docs/python/tf/keras/layers/Flatten?hl=zh_cn) 将图像格式从二维数组（28 x 28 像素）转换成一维数组（28 x 28 = 784 像素）。将该层视为图像中未堆叠的像素行并将其排列起来。该层没有要学习的参数，它只会重新格式化数据。

展平像素后，网络会包括两个 [`tf.keras.layers.Dense`](https://tensorflow.google.cn/api_docs/python/tf/keras/layers/Dense?hl=zh_cn) 层的序列。它们是密集连接或全连接神经层。第一个 `Dense` 层有 128 个节点（或神经元）。第二个（也是最后一个）层会返回一个长度为 10 的对数数组。每个节点都包含一个得分，用来表示当前图像属于 10 个类中的哪一类。

### ② 编译模型 compile

在准备对模型进行训练之前，还需要再对其进行一些设置。以下内容是在模型的*编译*步骤中添加的：

- *损失函数* `loss` - 用于测量模型在训练期间的准确率。您会希望最小化此函数，以便将模型“引导”到正确的方向上。

  > 💡 损失函数包含如下：
  >
  > [`class BinaryCrossentropy`](https://tensorflow.google.cn/api_docs/python/tf/keras/losses/BinaryCrossentropy): Computes the cross-entropy loss between true labels and predicted labels.
  >
  > [`class CategoricalCrossentropy`](https://tensorflow.google.cn/api_docs/python/tf/keras/losses/CategoricalCrossentropy): Computes the crossentropy loss between the labels and predictions.
  >
  > [`class CategoricalHinge`](https://tensorflow.google.cn/api_docs/python/tf/keras/losses/CategoricalHinge): Computes the categorical hinge loss between `y_true` and `y_pred`.
  >
  > [`class CosineSimilarity`](https://tensorflow.google.cn/api_docs/python/tf/keras/losses/CosineSimilarity): Computes the cosine similarity between labels and predictions.
  >
  > [`class Hinge`](https://tensorflow.google.cn/api_docs/python/tf/keras/losses/Hinge): Computes the hinge loss between `y_true` and `y_pred`.
  >
  > [`class Huber`](https://tensorflow.google.cn/api_docs/python/tf/keras/losses/Huber): Computes the Huber loss between `y_true` and `y_pred`.
  >
  > [`class KLDivergence`](https://tensorflow.google.cn/api_docs/python/tf/keras/losses/KLDivergence): Computes Kullback-Leibler divergence loss between `y_true` and `y_pred`.
  >
  > [`class LogCosh`](https://tensorflow.google.cn/api_docs/python/tf/keras/losses/LogCosh): Computes the logarithm of the hyperbolic cosine of the prediction error.
  >
  > [`class Loss`](https://tensorflow.google.cn/api_docs/python/tf/keras/losses/Loss): Loss base class.
  >
  > [`class MeanAbsoluteError`](https://tensorflow.google.cn/api_docs/python/tf/keras/losses/MeanAbsoluteError): Computes the mean of absolute difference between labels and predictions.
  >
  > [`class MeanAbsolutePercentageError`](https://tensorflow.google.cn/api_docs/python/tf/keras/losses/MeanAbsolutePercentageError): Computes the mean absolute percentage error between `y_true` and `y_pred`.
  >
  > [`class MeanSquaredError`](https://tensorflow.google.cn/api_docs/python/tf/keras/losses/MeanSquaredError): Computes the mean of squares of errors between labels and predictions.
  >
  > [`class MeanSquaredLogarithmicError`](https://tensorflow.google.cn/api_docs/python/tf/keras/losses/MeanSquaredLogarithmicError): Computes the mean squared logarithmic error between `y_true` and `y_pred`.
  >
  > [`class Poisson`](https://tensorflow.google.cn/api_docs/python/tf/keras/losses/Poisson): Computes the Poisson loss between `y_true` and `y_pred`.
  >
  > [`class Reduction`](https://tensorflow.google.cn/api_docs/python/tf/keras/losses/Reduction): Types of loss reduction.
  >
  > [`class SparseCategoricalCrossentropy`](https://tensorflow.google.cn/api_docs/python/tf/keras/losses/SparseCategoricalCrossentropy): Computes the <u>crossentropy（交叉熵）</u> loss between the labels and predictions.
  >
  > [`class SquaredHinge`](https://tensorflow.google.cn/api_docs/python/tf/keras/losses/SquaredHinge): Computes the squared hinge loss between `y_true` and `y_pred`.

- *优化器* `optimizer`- 决定模型如何根据其看到的数据和自身的损失函数进行更新。

- *指标*  `metrics` - 用于监控训练和测试步骤。以下示例使用了*准确率*，即被正确分类的图像的比率。

```python
model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])
```

## 5. 训练模型

训练神经网络模型需要执行以下步骤：

1. 将训练数据馈送给模型。在本例中，训练数据位于 `train_images` 和 `train_labels` 数组中。
2. 模型学习将图像和标签关联起来。
3. 要求模型对测试集（在本例中为 `test_images` 数组）进行预测。
4. 验证预测是否与 `test_labels` 数组中的标签相匹配。

### ① 向模型馈送数据 fit

要开始训练，请调用 `model.fit` 方法，这样命名是因为该方法会将模型与训练数据进行“拟合”：

> 💡 `model.fit()`
>
> ```python
> fit( x, y, batch_size=32, epochs=10, verbose=1, callbacks=None,
> validation_split=0.0, validation_data=None, shuffle=True, 
> class_weight=None, sample_weight=None, initial_epoch=0)123
> ```
>
> - `x`：输入数据。如果模型只有一个输入，那么x的类型是numpy array，如果模型有多个输入，那么x的类型应当为 list，list的元素是对应于各个输入的numpy array
> - `y`：标签，numpy array
> - `batch_size`：整数，指定进行梯度下降时每个batch包含的样本数。训练时一个batch的样本会被计算一次梯度下降，使目标函数优化一步。
> - `epochs`：整数，训练终止时的epoch值，训练将在达到该epoch值时停止，当没有设置initial_epoch时，它就是训练的总轮数，否则训练的总轮数为epochs - inital_epoch
> - `verbose`：日志显示，0为不在标准输出流输出日志信息，1为输出进度条记录，2为每个epoch输出一行记录
> - `callbacks`：list，其中的元素是keras.callbacks.Callback的对象。这个list中的回调函数将会在训练过程中的适当时机被调用，参考回调函数
> - `validation_split`：0~1之间的浮点数，用来指定训练集的一定比例数据作为验证集。验证集将不参与训练，并在每个epoch结束后测试的模型的指标，如损失函数、精确度等。注意，validation_split的划分在shuffle之前，因此如果你的数据本身是有序的，需要先手工打乱再指定validation_split，否则可能会出现验证集样本不均匀。
> - `validation_data`：形式为（X，y）的tuple，是指定的验证集。此参数将覆盖validation_spilt。
> - `shuffle`：布尔值或字符串，一般为布尔值，表示是否在训练过程中随机打乱输入样本的顺序。若为字符串“batch”，则是用来处理HDF5数据的特殊情况，它将在batch内部将数据打乱。
> - `class_weight`：字典，将不同的类别映射为不同的权值，该参数用来在训练过程中调整损失函数（只能用于训练）
> - `sample_weight`：权值的numpy array，用于在训练时调整损失函数（仅用于训练）。可以传递一个1D的与样本等长的向量用于对样本进行1对1的加权，或者在面对时序数据时，传递一个的形式为（samples，sequence_length）的矩阵来为每个时间步上的样本赋不同的权。这种情况下请确定在编译模型时添加了sample_weight_mode=’temporal’。
> - `initial_epoch`: 从该参数指定的epoch开始训练，在继续之前的训练时有用。
>
> `fit` 函数返回一个`History`的对象，其`History.history`属性记录了损失函数和其他指标的数值随epoch变化的情况，如果有验证集的话，也包含了验证集的这些指标变化情况

```python
model.fit(train_images, train_labels, epochs=10)
Epoch 1/10
1875/1875 [==============================] - 1s 591us/step - loss: 0.4973 - accuracy: 0.8251
Epoch 2/10
1875/1875 [==============================] - 1s 593us/step - loss: 0.3727 - accuracy: 0.8659
Epoch 3/10
1875/1875 [==============================] - 1s 604us/step - loss: 0.3323 - accuracy: 0.8769
Epoch 4/10
1875/1875 [==============================] - 1s 684us/step - loss: 0.3102 - accuracy: 0.8859
Epoch 5/10
1875/1875 [==============================] - 1s 632us/step - loss: 0.2904 - accuracy: 0.8923
Epoch 6/10
1875/1875 [==============================] - 1s 651us/step - loss: 0.2784 - accuracy: 0.8973
Epoch 7/10
1875/1875 [==============================] - 1s 618us/step - loss: 0.2665 - accuracy: 0.9003
Epoch 8/10
1875/1875 [==============================] - 1s 609us/step - loss: 0.2550 - accuracy: 0.9042
Epoch 9/10
1875/1875 [==============================] - 1s 608us/step - loss: 0.2463 - accuracy: 0.9085
Epoch 10/10
1875/1875 [==============================] - 1s 599us/step - loss: 0.2388 - accuracy: 0.9100
<tensorflow.python.keras.callbacks.History at 0x2593820d8c8>
```

在模型训练期间，会显示损失和准确率指标。此模型在训练数据上的准确率达到了 0.91（或 91%）左右。

### ② 在测试集上评估准确率 evaluate

接下来，比较模型在**测试数据集**上的表现：

```python
test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)

313/313 - 0s - loss: 0.3433 - accuracy: 0.8776
```

结果表明，模型在测试数据集上的准确率略低于训练数据集。表示模型出现了**过拟合**。过拟合是指机器学习模型在新的、以前未曾见过的输入上的表现不如在训练数据上的表现。过拟合的模型会“记住”训练数据集中的噪声和细节，从而对模型在新数据上的表现产生负面影响。关于【如何避免过拟合】请参见后续文章

## 6. 使用训练好的模型进行预测 predict

### ① 对于数据集的预测

在模型经过训练后，您可以使用它对一些图像进行预测 `predict`。模型具有线性输出，即对数 logits。

```python
# 预测整个测试集
predictions = model.predict(test_images)
```

> 💡 **您可以附加一个 softmax 层，将对数转换成更容易理解的概率**。
>
> ```python
> probability_model = tf.keras.Sequential([model, 
>                                          tf.keras.layers.Softmax()])
> predictions = probability_model.predict(test_images)
> ```

在上例中，模型预测了测试集中每个图像的标签。我们来看看对于测试集中第一个数据的预测结果：

```python
predictions[0]
array([-12.287166 , -12.227676 , -11.628488 , -23.456598 , -13.601996 ,
        -0.3401114, -11.226322 ,  -0.9587118, -10.683305 ,   3.9778895],
      dtype=float32)
```

如果是加入了 softmax 的层话会更加直观：

```python
probability_model = tf.keras.Sequential([model, 
                                         tf.keras.layers.Softmax()])
predictions = probability_model.predict(test_images)

predictions[0]
array([8.4598121e-08, 8.9783427e-08, 1.6346355e-07, 1.1927167e-12,
       2.2716266e-08, 1.3058711e-02, 2.4438737e-07, 7.0346999e-03,
       4.2063812e-07, 9.7990555e-01], dtype=float32)
```

预测结果是一个包含 10 个数字的数组。它们代表模型对 10 种不同服装中每种服装的“置信度”。您可以看到哪个标签的置信度值最大：

```python
np.argmax(predictions[0])
9
```

因此，该模型非常确信这个图像是短靴，或 `class_names[9]`。通过检查测试标签发现这个分类是正确的：

```python
test_labels[0]
9
```

您可以将其绘制成图表：

```python
# 绘制数据集 img 上的第 i 张图片的分类概率
# predictions_array 表示该张图片对应每个分类的概率
# true_label 表示该图片的真实标签
def plot_image(i, predictions_array, true_label, img):
  predictions_array, true_label, img = predictions_array, true_label, img[i]
  plt.grid(False)
  plt.xticks([])
  plt.yticks([])

  plt.imshow(img)

  predicted_label = np.argmax(predictions_array)
  if predicted_label == true_label:
    color = 'blue' # 正确的预测标签为蓝色
  else:
    color = 'red' # 错误的预测标签为红色

  plt.xlabel("{} {:2.0f}% ({})".format(class_names[predicted_label], # 标签
                                100*np.max(predictions_array), # 概率
                                class_names[true_label]), # 真实标签
                                color=color)
```

<img src="https://gitee.com/veal98/images/raw/master/img/20201104213705.png" style="zoom:50%;" />

```python
# 绘制第 i 张图片对应每个分类的概率
def plot_value_array(i, predictions_array, true_label):
  predictions_array, true_label = predictions_array, true_label
  plt.grid(False)
  plt.xticks(range(10))
  plt.yticks([])
  thisplot = plt.bar(range(10), predictions_array, color="#777777")
  plt.ylim([0, 1])
  predicted_label = np.argmax(predictions_array)

  thisplot[predicted_label].set_color('red')
  thisplot[true_label].set_color('blue')
```

<img src="https://gitee.com/veal98/images/raw/master/img/20201104214753.png" style="zoom:67%;" />

### ② 对于单个数据的预测

🚨 **[`tf.keras`](https://tensorflow.google.cn/api_docs/python/tf/keras?hl=zh_cn) 模型经过了优化，可同时对一个*批*或一组样本进行预测。因此，即便您只使用一个图像，您也需要将其添加到列表中**：

```python
img = test_images[1]

img = (np.expand_dims(img,0))
```

接下来的预测过程同上：

<img src="https://gitee.com/veal98/images/raw/master/img/20201104220136.png" style="zoom:67%;" />

## 7. 保存整个模型 save

调用 [`model.save`](https://tensorflow.google.cn/api_docs/python/tf/keras/Model?hl=zh_cn#save) 将保存模型的结构，权重和训练配置保存在单个文件/文件夹中。这可以让您导出模型，以便在不访问原始 Python 代码的情况下使用它。因为优化器状态（optimizer-state）已经恢复，您可以从中断的位置恢复训练。

整个模型可以以两种不同的文件格式（`SavedModel` 和 `HDF5`）进行保存。需要注意的是 TensorFlow 的 `SavedModel` 格式是 TF2.x. 中的默认文件格式。但是，模型仍可以以 `HDF5` 格式保存。下面介绍了以两种文件格式保存整个模型的更多详细信息。

### ① SavedModel 格式

SavedModel 格式是序列化模型的另一种方法。以这种格式保存的模型，可以使用 [`tf.keras.models.load_model`](https://tensorflow.google.cn/api_docs/python/tf/keras/models/load_model?hl=zh_cn) 还原，并且模型与 TensorFlow Serving 兼容。[SavedModel 指南](https://tensorflow.google.cn/guide/saved_model?hl=zh_cn)详细介绍了如何提供/检查 SavedModel。以下部分说明了保存和还原模型的步骤。

```python
# 将整个模型另存为 my_model
model.save('my_model') 
```

从保存的模型重新加载新的 Keras 模型：

```python
new_model = tf.keras.models.load_model('my_model')
```

我们可以使用 `new_model` 进行和 `model` 一样的操作。

### ② HDF5 格式

Keras使用 [HDF5](https://en.wikipedia.org/wiki/Hierarchical_Data_Format) 标准提供了一种基本的保存格式。

```python
# 将整个模型保存为 HDF5 文件。
# '.h5' 扩展名指示应将模型保存到 HDF5。
model.save('my_model.h5') 
```

现在，从该文件重新创建模型：

```python
# 重新创建完全相同的模型，包括其权重和优化程序
new_model = tf.keras.models.load_model('my_model.h5')
```

## 📚 References

- [TensorFlow 2 官方文档](https://tensorflow.google.cn/tutorials/keras/classification?hl=zh_cn)