# 🌌 CNN 的特殊应用：人脸识别和神经风格转换

---

> 🔈 本节将介绍一些重要的卷积神经网络的特殊应用，比如人脸识别、神经风格转换

## 1. 什么是人脸识别/验证 Face recognition / verification

首先，让我们了解一下人脸识别的一些术语：人脸验证（`face verification`）和人脸识别（`face recognition`）

- **人脸验证**：输入一张人脸图片，验证输出与模板是否为同一人，即一对一问题。
- **人脸识别**：输入一张人脸图片，验证输出是否为 K 个模板中的某一个，即一对多问题。

一般地，人脸识别比人脸验证更难一些。因为假设人脸验证系统的错误率是 `1%`，那么在人脸识别中，输出分别与 `K` 个模板都进行比较，则相应的错误率就会增加，约 `K%`。模板个数越多，错误率越大一些。

## 2. One-Shot学习 One-shot learning

人脸识别所面临的一个挑战就是你需要解决一次学习问题 One-shot learning，也就是说**数据库中每个人的训练样本只有一张照片**。通过训练一个 CNN 模型来进行人脸识别。若数据库有 K 个人，则 CNN 模型输出 softmax 层就是 K 维的。

但是 One-shot learning 的性能并不好，其包含了两个缺点：

- 每个人只有一张图片，训练样本少，构建的 CNN 网络不够健壮。
- 若数据库增加另一个人，输出层 softmax 的维度就要发生变化，相当于要重新构建 CNN 网络，使模型计算量大大增加，不够灵活。

为了解决 One-shot learning 的问题，我们先来介绍**相似函数（similarity function）**。**相似函数表示两张图片的相似程度，用 `d(img1,img2)` 来表示**。若 `d(img1,img2)` 较小，则表示两张图片相似；若 `d(img1,img2)` 较大，则表示两张图片不是同一个人。

<u>对于人脸识别问题，则只需计算测试图片与数据库中 `K` 个目标的相似函数，取其中 `d(img1,img2)` 最小的目标为匹配对象。若所有的 `d(img1,img2)` 都很大，则表示数据库没有这个人。</u>

![](https://gitee.com/veal98/images/raw/master/img/20201014104837.png)

那么，如何训练神经网络使得它学会这个相似函数 `d` ？👇

## 3. Siamese 网络 Siamese network

若一张图片经过一般的CNN网络（包括CONV层、POOL层、FC层），最终得到全连接层 FC，**该 FC 层可以看成是原始图片的编码 encoding，表征了原始图片的关键特征**。<u>对于两个不同的输入，运行相同的卷积神经网络，然后比较它们，这一般叫做 ***Siamese 网络** 架构</u>。**也就是说每张图片经过 `Siamese network` 后，由 FC 层的每个神经元来表征**。

![](https://gitee.com/veal98/images/raw/master/img/20201014105244.png)

建立 Siamese network后，两张图片 $x^{(1)}$ 和 $x^{(2)}$ 的相似度函数可由各自FC层 $f(x^{(1)})$ 与 $f(x^{(2)})$ 之差的范数来表示：

<img src="https://gitee.com/veal98/images/raw/master/img/20201014105339.png" style="zoom: 60%;" />

怎么训练这个 **Siamese** 神经网络呢 ？不要忘了这两张图片运行的是相同的卷积神经网络，所以这两个网络有相同的参数。**我们的目标就是利用梯度下降算法，不断调整网络参数，使得属于同一人的图片之间 $d(x^{(1)},x^{(2)})$ 很小，而不同人的图片之间 $d(x^{(1)},x^{(2)})$ 很大**：

<img src="https://gitee.com/veal98/images/raw/master/img/20201014105803.png" style="zoom:67%;" />

具体的网络构建和训练参数方法见下节 👇

## 4. 三元组损失 Triplet Loss

要想通过学习神经网络的参数来得到优质的人脸图片编码，方法之一就是**定义三元组损失函数然后应用梯度下降**。

`Triplet Loss` 需要每个样本包含三张图片：**靶目标（Anchor）、正例（Positive）、反例（Negative）**，这就是 `triplet `名称的由来。顾名思义，靶目标和正例是同一人，靶目标和反例不是同一人。**Anchor 和 Positive 组成一类样本，Anchor 和 Negative 组成另外一类样本**：

![](https://gitee.com/veal98/images/raw/master/img/20201014110126.png)

我们希望上一小节构建的 CNN 网络输出编码 f(A) 接近 f(P) ，即 $||f(A)-f(P)||^2$ 尽可能小，而 $||f(A)-f(N)||^2$ 尽可能大，数学上满足：

<img src="https://gitee.com/veal98/images/raw/master/img/20201014110211.png" style="zoom:62%;" />

💡 根据上面的不等式，如果所有的图片都是零向量，即 $f(A)=0,f(P)=0,f(N)=0$ ，那么上述不等式也满足。但是这对我们进行人脸识别没有任何作用，是不希望看到的。我们希望得到 $||f(A)-f(P)||^2$ 远小于 $||f(A)-F(N)||^2$ 。所以，我们**添加一个超参数 $\alpha$ ，且 $\alpha > 0$** ，对上述不等式做出如下修改：

<img src="https://gitee.com/veal98/images/raw/master/img/20201014110532.png" style="zoom:62%;" />

这里的 *α* 也被称为边界 margin，类似与支持向量机中的 margin。举个例子，若 $d(A,P)=0.5$，$α = 0.2$，则$d(A,N)≥0.7$。

接下来，我们根据一组训练图片，即A，P，N三张图片，就可以定义 **Loss function** 为：

<img src="https://gitee.com/veal98/images/raw/master/img/20201014111404.png" style="zoom:67%;" />

相应地，对于 m 组训练样本，**Cost function** 为：

<img src="https://gitee.com/veal98/images/raw/master/img/20201014111422.png" style="zoom:67%;" />

🚨 注意：**关于训练样本，必须保证同一人包含多张照片，否则无法使用这种方法**。

然后，就可以使用梯度下降算法，不断训练优化 CNN 网络参数，让 `J` 不断减小接近 0。

同一组训练样本，A，P，N 的选择尽可能不要使用随机选取方法。因为随机选择的A与P一般比较接近，A与N相差也较大，毕竟是两个不同人脸。这样的话，也许模型不需要经过复杂训练就能实现这种明显识别，但是抓不住关键区别。所以，⭐ **最好的做法是人为选择 `A` 与 `P` 相差较大（例如换发型，留胡须等），`A` 与 `N` 相差较小（例如发型一致，肤色一致等）**。这种人为地增加难度和混淆度会让模型本身去寻找学习不同人脸之间关键的差异，“尽力”让 d(A,P)更小，让 d(A,N) 更大，即让模型性能更好：

![](https://gitee.com/veal98/images/raw/master/img/20201014111813.png)

> 🔈 值得一提的是，现在许多商业公司构建的大型人脸识别模型都需要百万级别甚至上亿的训练样本。如此之大的训练样本我们一般很难获取。但是<u>一些公司将他们训练的人脸识别模型发布在了网上，可供我们使用</u>。

## 5. 人脸验证与二分类 Face verification and binary classification

除了构造 Triplet loss 来解决人脸识别问题之外，还可以使用**二分类结构**。做法是**将两个 siamese 网络组合在一起，将各自的编码层输出经过一个逻辑输出单元，该神经元使用 sigmoid 函数，输出 1 则表示识别为同一人，输出 0 则表示识别为不同人**。结构如下：

![](https://gitee.com/veal98/images/raw/master/img/20201014144116.png)

每组训练样本包含两张图片，每个 siamese 网络结构和参数完全相同。这样就把人脸识别问题转化成了一个二分类问题。引入逻辑输出层参数 w 和 b，输出 $\hat y$ 表达式为：

<img src="https://gitee.com/veal98/images/raw/master/img/20201014144200.png" style="zoom:67%;" />

其中参数 $w_k$ 和 $b$ 都是通过梯度下降算法迭代训练得到。

$\hat y$ 的另外一种表达式为：

<img src="https://gitee.com/veal98/images/raw/master/img/20201014144425.png" style="zoom:67%;" />

上式被称为 $\chi$ 方公式，也叫 $\chi$ 方相似度。

在训练好网络之后，进行人脸识别的常规方法是测试图片与模板分别进行网络计算，编码层输出比较，计算逻辑输出单元。为了减少计算量，可以**使用预计算的方式在训练时就将数据库每个模板的编码层输出 $f(x)$ 保存下来**。因为编码层输出 $f(x)$ 比原始图片数据量少很多，所以无须保存模板图片，只要保存每个模板的 $f(x)$ 即可，节约存储空间。而且，测试过程中，无须计算模板的 siamese 网络，只要计算测试图片的 siamese 网络，得到的 $f(x^{(i)})$ 直接与存储的模板 $f(x^{(j)})$ 进行下一步的逻辑输出单元计算即可，计算时间减小了接近一半。这种方法也可以应用在上一节的 triplet loss 网络中。

## 6. 什么是神经风格迁移 neural style transfer

神经风格迁移是CNN模型一个非常有趣的应用。它可以实现**将一张图片的风格“迁移”到另外一张图片中，生成具有其特色的图片**。

下面列出几个神经风格迁移的例子：

![](https://gitee.com/veal98/images/raw/master/img/20201014145215.png)

一般用 C 表示内容图片，S 表示风格图片，G 表示生成的图片。

## 7. CNN 特征可视化

<u>在进行神经风格迁移之前，我们先来从可视化的角度看一下卷积神经网络每一层到底是什么样子？它们各自学习了哪些东西，这样有助于理解如何实现神经风格迁移。</u>

典型的CNN网络如下所示：

![](https://gitee.com/veal98/images/raw/master/img/20201014145347.png)

首先来看第一层隐藏层，遍历所有训练样本，找出让该层激活函数输出最大的 9 块图像区域；然后再找出该层的其它单元（不同的滤波器通道）激活函数输出最大的 9 块图像区域；最后共找 9 次，得到 9 x 9 的图像如下所示，其中每个3 x 3区域表示一个运算单元。

![](https://gitee.com/veal98/images/raw/master/img/20201014145612.png)

可以看出，第一层隐藏层一般检测的是原始图像的边缘和颜色阴影等简单信息。

继续看CNN的更深隐藏层，随着层数的增加，捕捉的区域更大，特征更加复杂，从边缘到纹理再到具体物体。

![](https://gitee.com/veal98/images/raw/master/img/20201014145623.png)

## 8. 神经风格转换的代价函数

### ① J(G)

神经风格迁移生成图片 `G` 的 Cost function 由两部分组成：`C` 与 `G` 的相似程度和 `S` 与 `G` 的相似程度。

<img src="https://gitee.com/veal98/images/raw/master/img/20201014145842.png" style="zoom:67%;" />

神经风格迁移的基本算法流程是：**首先令 `G` 为随机像素点，然后使用梯度下降算法，不断修正 `G` 的所有像素点，使得 `J(G)` 不断减小**，从而使 `G` 逐渐有 `C` 的内容和 `G` 的风格，如下图所示：

![](https://gitee.com/veal98/images/raw/master/img/20201014145922.png)

### ② J_content (C, G)

我们先来看 `J(G)` 的第一部分 $J_{content}(C,G)$ ，它表示内容图片 `C` 与生成图片 `G` 之间的相似度。

<img src="https://gitee.com/veal98/images/raw/master/img/20201014150426.png" style="zoom: 62%;" />

### ③ J_style (S, G)

什么是图片的风格？利用 CNN 网络模型，**图片的风格可以定义成第 l 层隐藏层不同通道间激活函数的乘积（相关性）**:

![](https://gitee.com/veal98/images/raw/master/img/20201014151839.png)

例如我们选取第 l 层隐藏层，其各通道使用不同颜色标注，如下图所示。因为每个通道提取图片的特征不同，比如1 通道（红色）提取的是图片的垂直纹理特征，2 通道（黄色）提取的是图片的橙色背景特征。那么计算这两个通道的相关性大小，相关性越大，表示原始图片及既包含了垂直纹理也包含了该橙色背景；相关性越小，表示原始图片并没有同时包含这两个特征。也就是说，计算不同通道的相关性，反映了原始图片特征间的相互关系，从某种程度上刻画了图片的“风格”。

![](https://gitee.com/veal98/images/raw/master/img/20201014151859.png)

接下来我们就可以定义图片的风格矩阵（style matrix）为：

<img src="https://gitee.com/veal98/images/raw/master/img/20201014152302.png" style="zoom:60%;" />

## 9. 一维到三维推广

我们之前介绍的CNN网络处理的都是2D图片，举例来介绍**2D**卷积的规则：

![](https://gitee.com/veal98/images/raw/master/img/20201014152625.png)

- 输入图片维度：14 x 14 x 3
- 滤波器尺寸：5 x 5 x 3，滤波器个数：16
- 输出图片维度：10 x 10 x 16

将2D卷积推广到**1D**卷积，举例来介绍1D卷积的规则：

![](https://gitee.com/veal98/images/raw/master/img/20201014152644.png)

- 输入时间序列维度：14 x 1
- 滤波器尺寸：5 x 1，滤波器个数：16
- 输出时间序列维度：10 x 16

对于**3D**卷积，举例来介绍其规则：

![](https://gitee.com/veal98/images/raw/master/img/20201014152719.png)

- 输入3D图片维度：14 x 14 x 14 x 1
- 滤波器尺寸：5 x 5 x 5 x 1，滤波器个数：16
- 输出3D图片维度：10 x 10 x 10 x 16

## 📚 Reference

- [黄海广 - Coursera 深度学习教程中文笔记](https://github.com/fengdu78/deeplearning_ai_books)
- [红色石头 - 吴恩达 deeplearning.ai 专项课程精炼笔记](https://redstonewill.com/category/ai-notes/andrew-deeplearning-ai/page/2/)