# 🍠 算法基础

---

## 1. 什么是算法

<img src="https://gitee.com/veal98/images/raw/master/img/20201130144420.png" style="zoom:60%;" />

**算法 alogorithm** 就是定义解决问题的计算过程，该过程去某个值或值的集合作为**输入 Input**，并产生某个值或值的集合作为**输出 Output**。这样算法就是把输入转换成输出的计算步骤的一个序列。

⭐ **算法 + 数据结构 = 程序**。

算法只有在合适的数据结构中才能发挥作用，数据结构的不同，会影响算法的选择和效率。

<u>一般认为，算法是由若干条指令组成的有穷序列，具有下列五个特性</u>：

- 确定性：每条指令都是明确的、无二义的

- 可行性：每条指令都必须是能够执行的

- 输入：允许有0个或多个输入量，取自特定的集合

- 输出：产生一个或多个输出，它（们）与输入量之间存在着某种特定的关系

- 有穷性：每一条指令执行的次数都是有穷的

## 2. 分析算法

我们可以从以下几个方面去分析算法：

### ① 问题的规模

**问题的规模**也即**输入规模**：将一个或多个整数，作为输入数据量的测度

比如，在一个数组中寻找 X，那么这个问题的规模就是这个数组的长度

### ② 占支配地位的运算

一般来说，我们分析算法的时候，关心的是该算法中占支配地位的运算。

比如说，在一个表中寻找数据元素 X，那么这个问题中占支配地位的运算就是 X 与表中的每一个项进行比较

再比如，对一个数组进行排序，那么这个问题中占支配地位的运算就是表中的两个数据项进行比较。

### ③ 时间复杂度

![](https://gitee.com/veal98/images/raw/master/img/20201130145255.png)

<u>用问题规模的某个函数来表示算法的基本执行次数, 这个表示基本执行次数的函数称为算法的时间复杂性（度）</u>，时间复杂度用 `T(n)` (或 `T(n,m)` 等) 来表示

👇 根据定义，可以归纳出基本的计算步骤：

- 计算出基本操作的执行次数 `T(n)`

  基本操作即算法中的每条语句（以 `;` 号作为分割），语句的执行次数也叫做语句的频度。在做算法分析时，一般默认为考虑最坏的情况。

-  计算出 T(n) 的数量级：即忽略常量、低次幂和最高次幂的系数。令 `f(n)=T(n)` 的数量级

💬 举个最简单的例子：

```java
sum=0；                 
for(i=0;i<n;i++)       
	sum++；
```

上面代码中第一行频度 1，第二行频度为 n，第三行频度为 n，所以 T(n) = n+n+1 = 2n+1。忽略常量、低次幂和最高次幂的系数，则 f(n)  = n

#### 渐进时间复杂度

所谓渐进时间复杂度就是**当问题的规模趋于极限情形时（相当大）的时间复杂度**

对于算法进行特别具体的细致分析虽然很好，但在实践中的实际价值有限。对于算法的时间性质和空间性质，最重要的是其数量级和趋势，这些是分析算法效率的主要部分。而计量算法基本操作数量的规模函数中那些常量因子可以忽略不计。例如，可以认为 $3n^2$ 和 $100n^2$ 属于同一个量级，如果两个算法处理同样规模实例的代价分别为这两个函数，就认为它们的效率“差不多”，都为 $n^2$ 级。

<u>即当 n 趋近于无穷大时，如果 $lim \frac{T(n)}{f(n)}$ 的值为不等于 0 的常数，则称 `f(n)` 是 `T(n)` 的同数量级函数。记作 `T(n) = O/Ω/Θ(f(n))`</u> 

表示渐近时间复杂度的三个记号：

- `T(n) = O(f(n))`

  对于给定的函数 f(n)，若存在 $c > 0$，和正整数 $n_0 ≥ 1$，使得当 $n≥n_0$ 时，总有 $T(n)≤c * f(n)$

  该记法给出了算法时间复杂度的**上界**，复杂度不可能比 $c*f(n)$ 更大

  比如 $T(n)=O(n^2)$ 表示该算法运行时间不会超过 $cn^2$

- `T(n) = Ω(f(n))`

  若存在 $c > 0$，和正整数 $n_0≥1$，使得当 $n≥n_0$ 时，存在无穷多个 n ，使得 $T(n)≥c*f(n)$ 成立

  该记法给出了算法时间复杂度的**下界**，复杂度不可能比 $c*f(n)$ 更小

  比如 $T(n)=Ω(n^2)$ 表示该算法运行时间不会低于 $cn^2$

- `T(n) = Θ(f(n))`

  若存在 $c1,c2>0$，和正整数 $n_0≥1$，使得当 $n≥n_0$ 时，总有 $T(n)≤c1*f(n)$，且有无穷多个 n，使得$T(n)≥c2*f(n)$成立, 即：`T(n) = O(f(n))`与`T(n) = Ω(f(n))`都成立

  该记法既给出了算法时间复杂度的**上界**，也给出了**下界**

  比如：$T(n)=Θ(n^2)$ 表示该算法的运行时间不会超过 $c_1n^2$ ，不会低于 $c_2n^2 $

三种记法的图示如下：

<img src="https://gitee.com/veal98/images/raw/master/img/20200915203916.png" style="zoom: 50%;" />

👇 归纳出基本的渐进时间复杂度的计算步骤：

- 计算出基本操作的执行次数 `T(n)`

  基本操作即算法中的每条语句（以 `;` 号作为分割），语句的执行次数也叫做语句的频度。在做算法分析时，一般默认为考虑最坏的情况。

-  计算出 T(n) 的数量级：即忽略常量、低次幂和最高次幂的系数。令 `f(n)=T(n)` 的数量级
- 用 `O/Ω/Θ` 来表示渐进时间复杂度

举个例子：

```java
int num1, num2; 
for(int i=0; i<n; i++){ 
    num1 += 1;  
    for(int j=1; j<=n; j*=2){  
        num2 += num1; 
    }
}
```

- 首先计算基本操作的执行次数：

  `int num1, num2;` 频度 = 1

  `for(int i=0; i<n; i++)` 中 `int i = 0` 频度 = 1；`i<n; i++` 两条语句的频度都为 n

  同样的，循环体内的语句 `num1 += 1;` 频度 = n

  嵌套循环 `for(int j=1; j<=n; j*=2)` 中 `int j = 1` 频度 = n；`j<=n; j*=2` 两条语句的频度都为 n*log2n

  同样的，循环体内的语句 `num2 += num1;` 频度 = n*log2n

  => $T(n) = 1 + 1 + n + n + n + n + 3n*log2n = 2 + 4n + 3n*log2n$

- 然后忽略掉T(n)中的常量、低次幂和最高次幂的系数：$f(n) = n*log2n$

- 最后，取渐进时间复杂度：

  $lim(T(n)/f(n)) = 2*(1/n)*(1/log2n) + 4*(1/log2n) + 3$

  当 n 趋向于无穷大，1/n 趋向于0，1/log2n 趋向于0，所以极限等于 3 不等于 0，则称 `f(n)` 是 `T(n)` 的同数量级函数 => $T(n) = O(n*log2n)$

#### 常见的渐进时间复杂度

大 O 记法的运算规则：

<img src="https://gitee.com/veal98/images/raw/master/img/20201003154506.png" style="zoom:50%;" />

<img src="https://gitee.com/veal98/images/raw/master/img/20200915211639.png" style="zoom: 67%;" />

运行效率（越小越好）：

⭐ $O(1)<O(logn)<O(n)<O(nlogn)<O(n^2)<O(n^3)<O(2^n)<<O(n!)<O(n^n)$

![](https://gitee.com/veal98/images/raw/master/img/20200915211134.png)

👇 下面对不同的量级给出一个具体的例子：

🔴 **常数阶 O(1)**

无论代码执行了多少行，<u>只要是没有循环等复杂结构，那这个代码的时间复杂度就都是 O(1)</u>，如：

```java
int i = 1;
int j = 2;
++i;
j++;
int m = i + j;
```

上述代码在执行的时候，它消耗的时候并不随着某个变量的增长而增长，那么无论这类代码有多长，即使有几万几十万行，都可以用 O(1) 来表示它的时间复杂度。

🔴 **线性阶 O(n)**

```java
for(i=1; i<=n; ++i){
   j = i;
   j++;
}
```

这段代码，`for `循环里面的代码会执行 n 遍，因此它消耗的时间是随着 n 的变化而变化的，因此这类代码都可以用 O(n) 来表示它的时间复杂度。

🔴 **对数阶 O(logN)**

还是先来看代码：

```java
int i = 1;
while(i < n){
    i = i * 2;
}
```

从上面代码可以看到，在 `while `循环里面，<u>每次都将 i 乘以 2，乘完之后，i 距离 n 就越来越近了</u>。我们试着求解一下，假设循环 x 次之后，i 就大于 2 了，此时这个循环就退出了，也就是说 2 的 x 次方等于 n，那么 $x = log2^n$,也就是说当循环 $log2^n$ 次以后，这个代码就结束了。因此这个代码的时间复杂度为：O(logn)

🔴 **线性对数阶 O(nlogN)**

线性对数阶 O(nlogN) 其实非常容易理解，将时间复杂度为 O(logn) 的代码循环 N 遍的话，那么它的时间复杂度就是 n * O(logN)，也就是 O(nlogN)。

就拿上面的代码加一点修改来举例：

```java
for(m=1; m<n; m++){
    i = 1;
    while(i<n){
        i = i * 2;
    }
}
```

🔴 **平方阶 O(n²)**

平方阶 O(n²) 就更容易理解了，如果把 O(n) 的代码再嵌套循环一遍，它的时间复杂度就是 O(n²) 了：

```java
for(x=1; i<=n; x++)
{
   for(i=1; i<=n; i++)
    {
       j = i;
       j++;
    }
}
```

这段代码其实就是嵌套了 2 层 n 循环，它的时间复杂度就是 O(n*n)，即 O (n²)

如果将其中一层循环的 n 改成 m，即：

```java
for(x=1; i<=m; x++){
   for(i=1; i<=n; i++){
       j = i;
       j++;
    }
}
```

那它的时间复杂度就变成了 O(m*n)

#### 最坏/最好/平均时间复杂度

**最坏时间复杂度**：在规模为 n 的所有输入中，基本运算执行次数为最多的时间复杂度

**最好时间复杂度**：在规模为 n 的所有输入中，基本运算执行次数为最少的时间复杂度

**平均时间复杂度**：在规模为 n 的所有输入中，算法时间复杂度的平均值。一般假设每种输入情况以等概率出现。（其实我们上面讨论的渐进时间复杂度就是平均时间复杂度）

以顺序查找为例：

```java
public int find(int[] arr, int target) {
    int n = arr.length;
    for (int i = 0; i < n; i++) {
        // 依次遍历数组，如果找到和目标元素相同的值，在返回该值所在下标
        if (arr[i] == target) {
            return i;
        }
    }
    return -1;
}
```

- 最好情况时间复杂度：目标元素刚好在数组**第一个位置**，那么只需要一次就能找到，时间复杂度很明显是常量阶 O(1)

- 最坏情况时间复杂度：目标元素在数组**最后一个位置**或者**不在数组中**，那么得需要遍历完整个数组才能得出结果，时间复杂度为 O(n)

- 平均时间复杂度：根据大 O 记法，T(n) = O(n)

### ④ 空间复杂度

**一个程序的空间复杂度是指运行完一个程序所需内存的大小**。利用程序的空间复杂度，可以对程序的运行所需要的内存多少有个预先估计。一个程序执行时除了需要存储空间和存储本身所使用的指令、常数、变量和输入数据外，还需要一些对数据进行操作的工作单元和存储一些为现实计算所需信息的辅助空间。程序执行时所需存储空间包括以下两部分。

- 固定部分。这部分空间的大小与输入/输出的数据的个数多少、数值无关。主要包括指令空间（即代码空间）、数据空间（常量、简单变量）等所占的空间。这部分属于静态空间。

- 可变空间，这部分空间的主要包括动态分配的空间，以及递归栈所需的空间等。这部分的空间大小与算法有关。

<u>目前来说，除了在一些特殊情况下，我们都是更加注重时间复杂度，而不是空间复杂度。</u>

## 3. NP 完全性理论

![](https://gitee.com/veal98/images/raw/master/img/image-20201130160109339.png)

![](https://gitee.com/veal98/images/raw/master/img/20201130160529.png)

### ① 基本概念

**多项式（Polynomial）时间**：对规模为 n 的输入，算法在最坏情况下的计算时间为 $O(n^k)$。将可由多项式时间算法求解的问题看作为易解的问题，将需要超多项式时间时间才能求解的问题看作难解的问题。

<img src="https://gitee.com/veal98/images/raw/master/img/20201130150625.png" style="zoom:40%;" />

**判定问题**：判断是否有一种能够解决某一类问题的能行算法的研究课题。<u>回答是 Yes 或 No</u>

> 💡 **证书 certificate**：若集合 S 包含判定问题 A 的所有解，则称 S 是 A 的**证书集**，S 中的元素称为 A 的一个**证书**（certificate，注意**证书不一定是解**）

**最优化问题**（不是 Yes-No 问题）可以与一个判定问题相对应

- 比如：最优化问题：团集问题(CLIQUE)：任给一个无向图 G，<u>找出 G 中最大的团集</u>。团集：点的集合，满足：任两点之间均有边相连

  对应的判定问题：G 中<u>是否有</u> k- 团（k 个顶点的团集）

**非确定性多项式时间**：非确定性算法将问题分解为猜测和验证两个阶段。算法的猜测阶段是非确定性的，给出问题解的一个猜测。算法的验证阶段是确定性的，验证猜测阶段给出的解的正确性。<u>设算法 A 是解一个判定问题 Q 的非确定性算法，如果 A 的验证阶段能在多项式时间内完成，则称 A 是一个多项式时间非确定性算法，也称问题 Q 是非确定性多项式时间可解的。</u>

比如，找大质数的问题。有没有一个公式，你一套公式，就可以一步步推算出来，下一个质数应该是多少呢？这样的公式是没有的。再比如，大的合数分解质因数的问题，有没有一个公式，把合数代进去，就直接可以算出，它的因子各自是多少？也没有这样的公式。这种问题的答案，是无法直接计算得到的，只能通过间接的“猜算”来得到结果。这也就是非确定性问题。而这些问题的通常有个算法，它不能直接告诉你答案是什么，但可以告诉你，某个可能的结果是正确的答案还是错误的。这个可以告诉你“猜算”的答案正确与否的算法，假如可以在多项式时间内算出来，就叫做多项式非确定性问题。

> 🗨 举个例子：Hamiltonian 问题：
>
> <img src="https://gitee.com/veal98/images/raw/master/img/20201130155523.png" style="zoom:40%;" />
>
> <img src="https://gitee.com/veal98/images/raw/master/img/20201130155539.png" style="zoom:30%;" />

### ② P 类问题

🔸 **P 类问题（Polynomial Problem）**：所有可以在 多项式时间 内求解的 判定问题 构成 P 类问题。

### ③ NP 类问题

🔸 **NP 类问题（Non-deterministic Polynomial Problem）**：所有的 非确定性多项式时间 可解的 判定问题 构成 NP 类问题。

对于一个问题，如果我们能够在多项式时间内解决，那么我们肯定也能在多项式时间内验证某个猜测是否为这个问题的一个解，因此 **P 问题也属于 NP 问题**，或者说 P 问题是 NP 问题的一个子集。

⭐ 简单来说，**P 问题是容易解决的问题，NP 问题是容易验证的问题，NP 问题包含 P 问题，但是 NP 是否可以等于 P 至今未解**。 

### ④ NP 完全问题

#### Ⅰ 规约 Reducibility

在学习 NP 完全问题 之前，我们先了解**规约 Reducibility**的概念：

定义一个问题P可以归约到另一个问题Q，即解决 Q 的方法也可以用来解决P。这也就是说，如果我找到了解决问题Q的算法，那么这个算法也可以解决问题P。因此我们可以知道问题P一定不比问题Q要难，至少它们两个是同样难度的。

看下面两组问题。

> **1.a** 已知北京，上海，深圳，昆明，长沙，武汉，西安，台湾这八座城市中任意两座城市之间的机票价格。现在隔壁老王从北京出发，飞到其他七座城市（每个城市都要去一趟），最后回到北京。求是否存在机票总开销小于10000块的旅行方案？
>
> **1.b** 已知北京，上海，深圳，昆明，长沙，武汉，西安，台湾这八座城市中任意两座城市之间的机票价格。现在隔壁老王从北京出发，飞到其他七座城市（每个城市都要去一趟），最后回到北京。求所有旅行方案中机票总开销最少为多少钱？

> **2.a** 现有N个人要乘坐电梯到楼上，他们的体重分别为a1,a2, … ,an，电梯足够宽敞，不过最大的载重为M，试问是否存在一种方案使得电梯往返次数不多于t次，并且将这N个人全部送上楼？
>
> **2.b** 现有N个人要乘坐电梯到楼上，他们的体重分别为a1,a2, … ,an，电梯足够宽敞，不过最大的载重为M，要求设计一种方案将这N个人全部送上楼，并且电梯往返次数最少？
>
> **2.c** 在某港口放有N个集装箱，它们需要通过海运送到另一港口。已知其中第i个集装箱的长宽高和重量分别为Li,Wi,Hi,Mi。负责运载的轮船其货仓的长宽高和载重分别为L,W,H,M。要求设计一种方案将这些集装箱全部海运到另一港口，并且使用的轮船数目最少。

在第一组问题中，如果我们知道了问题1.b的解，那我们也就知道了问题1.a的解。并且用来求解问题1.b的方法也可用在求解问题1.a上。因此这组问题中，1.a可以归约到1.b

同样，在第二组问题中，如果我们知道了问题2.b的解，那我们也就知道了问题2.a的解。如果我们能解出2.c，那么我们也一定能解出2.b，然后解出2.a。这里主要是想强调一下归约的可传递性：**如果P可归约到Q，Q可归约到R，那么P可以归约到R**。

#### Ⅱ NP 完全问题

🔸 **NP-C 类问题（NP 完全问题）**：<u>简单的写法就是 `NP = P？`有没有这样一种 NP 问题，所有的 NP 问题都可以归约到它。也就是说，解决了这个问题，也就同时解决了所有的 NP 问题。即 `P = NP`</u>。不过，**目前还没有一个 NPC 类问题有多项式时间算法，即还无法证明 NP = P**。

> 在 1971 年，斯蒂芬·库克找到了第一个这样的问题：**可满足性问题**。简要来说，就是对于N个布尔类型的变量，它们之间采用“与”，“或”，“非”这样的逻辑运算符连接，那么这些变量能否找到一组合适的取值，使得最终的运算结果为真。与之相同的是逻辑电路问题，它其实就是可满足性问题的数字电路实现，用高电平和低电平表示真和假，用与门，或门和非门表示逻辑运算符。
>
> 伯克利的教授理查德·卡普在读过库克的论文之后，发现有一种方法可以**把可满足性问题归约到团问题**。团问题大致是这样一类问题：对于任意两个人，要么是微信好友，要么不是微信好友。那么能否找到一个人数为50个人的团体，使得他们两两之间彼此都是微信好友？因为库克证明了可满足性问题是NP问题中最难的问题，而卡普得到的则是，团问题不比可满足性问题要简单，至少它们一样难。卡普不仅证明了团问题是NP问题中最难的一个，而且他还找到了19个同样难度的重要问题，比如哈密顿回路，旅行商问题，最大割问题等等。1972年，他在他的论文《Reducibility Among Combinatorial Problems》中，提出了这 21 个 NP 中最难的问题，后来被称为 NP 完全问题。

现在的很多设计都是基于 `P ≠ NP` 之上的，那么假如某一天某一位大牛证明了 `P = NP`，那将对我们的生活产生怎样的改变呢？

举几个栗子：在生物学方面，我们能够很快地完成基因测序工作；对于一个机器学习系统，能够很快的得到令人满意的特征选择；如果从犯罪现场提取到罪犯的DNA，我们能在第一时间确定他是谁。不过，这也同样会带来问题：比如当前信息在网络传输中使用MD5来校验，以检查是否在中途被篡改，在 P=NP 之后，这种校验方式就不再可靠了。同样，对于RSA加密算法，也可以很快地计算出密钥。因为RSA是基于计算大数的乘法和除法很容易，而对大数进行因式分解非常难而设计的，因式分解被认为是NP问题。

#### Ⅲ 典型的 NP 完全问题

下面介绍几个典型的 NP 完全问题：

<img src="https://gitee.com/veal98/images/raw/master/img/20201130212910.png" style="zoom: 55%;" />

### ⑤ NP 难问题

前面说过 NPC 问题是 NP 问题中最难的一类问题，那么比 NPC 问题还要难的问题是什么样子呢？**首先可以由NPC 问题归约到它，其次它不一定是 NP 问题。这一类问题称为 NP 难问题（NP-Hard）。**

前面说过如果 P=NP，那么所有的NP问题都存在有效的解决方案，而**对于 NP 难问题来说，即使 P=NP，也不一定存在有效的解决方案**。

<img src="https://gitee.com/veal98/images/raw/master/img/20201003172050.png" style="zoom: 50%;" />

## 4. 近似算法

<img src="https://gitee.com/veal98/images/raw/master/img/20201201100553.png" style="zoom:67%;" />

### ① 什么是近似算法

迄今为止，所有的 **NP 完全问题**，均未能找到多项式时间的算法，故当问题规模较大时，求得最优的精确解的可能性很小。在此情况下，**往往退而去求比最优精确解稍差一点的解作为问题的近似答案**

### ② 近似算法性能比

近似算法一般都比较简单，但设计近似算法时必须关注**设计的算法所得到的近似解与最优解之间的差距**到底有多大

若一个最优化问题的最优值为 `c*​`，求解该问题的一个近似算法求得的近似最优解相应的目标函数值为 `c`，则将该近似算法的**近似比**定义为 `max{c*/c, c/c*}`

在通常情况下，近似比是问题输入规模 n 的一个函数 `ρ(n)`，即 `max{c*/c, c/c*} ≤ ρ(n)`

因此，**当近似比为 1 时，近似解就是最优解。近似比越大，则近似解越差**

### ③ 近似方案/模式 Approximation Scheme

很多问题已经设计出具有较小的固定**常数近似比**的多项式时间近似算法。比如顶点覆盖问题和旅行商问题，他们的近似算法的近似比为 2

对于另一些问题，**在其已知的最佳多项式时间近似算法中，近似比是输入规模 n 的函数，随着 n 的变化而变化**，比如**集合覆盖问题**就属于这类问题。

一些 NP 完全问题可以采用特定的多项式时间近似算法求解，这些算法**通过消耗更多的计算时间，可以得到不断缩小的近似比**。比如**子集和问题**就属于这类问题。

一个**最优化问题**的**近似模式**就是这样一种特定的多项式时间近似算法。该模式法以问题的规模 n 和 正数 ε 为输入，使得对任何固定的 ε，该模式都是一个 （1+ε）的近似算法。

💧 近似模式分为以下两种：

- **多项式时间近似模式 PTAS**, Polynomial Time Approximation Scheme

  如果<u>对任何固定的 ε > 0，该模式都以其输入实例规模 n 的多项式时间运行</u>，则称此模式为多项式时间近似模式

  <img src="https://gitee.com/veal98/images/raw/master/img/20201130215011.png" style="zoom:50%;" />

- **完全多项式时间近似模式 FPTAS**, Fully Polynomial Time Approximation Scheme

  如果某个近似模式的<u>运行时间表达式既为 1 / ε 的多项式，又为输入实例规模 n 的多项式</u>，则称其为完全多项式时间近似模式。例如 <img src="https://gitee.com/veal98/images/raw/master/img/20201130215229.png" style="zoom:50%;" />

⭐ 总结一下近似方案/模式，有以下三种：

- 常数近似比的近似算法
- 多项式时间近似方案
- 完全多项式时间近似方案

### ④ 顶点覆盖问题 Vertex-Cover Problem

顶点覆盖问题是一个 NP 完全的最小化问题，可找到一个**常数近似比 = 2** 的近似算法

<img src="https://gitee.com/veal98/images/raw/master/img/20201130220307.png" style="zoom:50%;" />

也就是说，**从无向图 G 中任意选一条边，该边上的两个顶点至少有一个在输出的顶点集 V' 中**。如下，红色的点集即为最小顶点覆盖

<img src="https://gitee.com/veal98/images/raw/master/img/20201130221054.png" style="zoom: 80%;" />

虽然在一个图中寻找最优顶点覆盖比较困难，但是找出近似最优的顶点覆盖还是相对容易的，下面给出一个近似算法，<u>该算法得出的顶点覆盖的规模不超过最优顶点覆盖规模的 **2 倍**</u>。如下：

```java
VertexSet approxVertexCover ( Graph g ) { 
     C = null;
     e1 = g.e;// 图 g 边的集合 e1
     while (e1 != null) { 
         从 e1 中任取一条边(u,v);
         C = C ∪ {u,v};
         从 e1 中删去与 u 和 v 相关联的所有边;
     } 
     return C;
}
```

<img src="https://gitee.com/veal98/images/raw/master/img/20201130222636.png" style="zoom: 50%;" />

上例的最优顶点覆盖其实仅仅包含 3 个顶点：b、d、e

### ⑤ 旅行商问题 Traveling-Salesman Problem

<img src="https://gitee.com/veal98/images/raw/master/img/20201130223531.png" style="zoom:50%;" />

下面我们给出**满足三角不等式的旅行商问题**的近似算法（利用最小生成树算法）：

```java
void approxTSP (Graph g){
    (1)选择 g 的任一顶点 r;
    (2)用 Prim 算法找出带权图g的一棵以r为根的最小生成树T;
    (3)前序遍历树 T 得到的顶点表L;
    (4)将 r 加到表 L 的末尾，按表L中顶点次序组成回路H，作为计算结果返回;
} 
```

 举个例子，假设两点之间的距离就是该边的代价：

<img src="https://gitee.com/veal98/images/raw/master/img/20201130224605.png" style="zoom: 67%;" />

图 b 是根据 Prim 算法找出的以 a 为根节点的最小生成树。图 c 是该最小生成数的先序遍历顺序。图 d 是该算法的旅行路线。

<u>上述算法求出的只是近似最优路线，其代价不大于真正最优旅行路线代价的 **2 倍**，即该近似算法的常数近似比 = 2</u>。

真正的最优旅行路线如下，它比图 d 的旅行路线代价要少约 23%：

<img src="https://gitee.com/veal98/images/raw/master/img/20201130224804.png" style="zoom:67%;" />

> 💡 在代价函数不一定满足三角不等式的一般情况下，**不存在**具有常数近似比的解 TSP 问题的多项式时间近似算法，除非 `P=NP`
>
> 换句话说，**若 `P≠NP`，则对任意常数 `ρ>1`，不存在近似比为 `ρ` 的求解旅行商问题的多项式时间近似算法** 

## 💯 课后习题

> 🔈 题目来源 《计算机算法与分析 王晓东 - 第5版》

### ① 求下列函数的渐进表达式

- $3n^2 + 10n$

  $< 3n^2 + 10n^2 = 13n^2 = O(n^2)$

- $n^2 / 10 + 2^n$

  $< 2^n + 2^n = 2*2^n = O(2^n)$

- $21 + 1/n$

  $< 21 + 1 = 22 = O(1)$

- $log(n^3)$

  $=3log(n)=O(log(n))$

- $10log(3^n)$

  $= (10log3)n = O(n) $

### ② O(1) 和 O(2) 的区别

O(1) = O(2)，用 O(1) 、O(2) 表示同一个函数时，差别仅在于其中的常数因子。

### ③ 求函数渐进阶

<img src="https://gitee.com/veal98/images/raw/master/img/20201003161240.png" style="zoom: 45%;" />

- （1）由于 $logn^2$ 和 $logn + 5$ 并无直接的大小关系， $logn^2$ 可能小于某个常数乘以 $logn + 5$，也可能大于某个常数乘以 $logn + 5$。所以 $f(n) =θ(g(n))$

- （2）$log(n) < √n$，$f(n) = 2log(n) < 2 * √n = 2 * g(n)$。所以 $f(n) = O(g(n))$

- （3）$log(n) < n$， $f(n) = n > 2 * log(n) = 1 * g(n)$。所以 $f(n) =  Ω(g(n))$

- （4）$f(n) =  Ω(g(n))$

- （5）常数级别的比较： $f(n) =θ(g(n))$

- （6）$f(n) =  Ω(g(n))$

- （7）$2^n > n^2$，$f(n) > 1/100 * g(n)$。所以 $f(n) =  Ω(g(n))$

- （8）$2^n < 3^n$。所以 $f(n) =  O(g(n))$

### ④ n! 的阶

n! = $O(n^n)$

### ⑤ 3n + 1 问题

<img src="https://gitee.com/veal98/images/raw/master/img/20201130162244.png" style="zoom:67%;" />

在最坏情况下，该算法的时间复杂度下界为 Ω(logn)

<img src="https://gitee.com/veal98/images/raw/master/img/20201130162440.png" style="zoom:40%;" />

## 📚 References

- 《算法导论 — 第 3 版 机械工业出版社》
- 《计算机算法与分析 王晓东 - 第5版》
- [NP 完全性理论简介](https://blog.csdn.net/liusiqian0209/article/details/49837447)
- [算法时间复杂度的计算 [整理]](https://www.iteye.com/blog/univasity-1164707)
- [算法—时间复杂度](https://blog.csdn.net/user11223344abc/article/details/81485842)
- [最好、最坏、平均、均摊时间复杂度分析](https://blog.csdn.net/weixin_38483589/article/details/84262167)